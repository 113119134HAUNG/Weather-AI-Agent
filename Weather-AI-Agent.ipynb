{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **警告：該資料庫和工具皆為本人所製，請勿任意下載。**F113119134 高雄科技大學"
      ],
      "metadata": {
        "id": "EjPjUrgTO9GB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "piKeY0lFNfIf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4713f4d-2c3c-49a6-f3ed-89b388c0cd74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "全部安裝完畢!\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/113119134HAUNG/Weather-AI-Agent.git> /dev/null 2>&1 && \\\n",
        "!!bash install.sh > /dev/null 2>&1 && \\\n",
        "echo \"全部安裝完畢!\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLoXTRx6OhnE"
      },
      "source": [
        "# **1. 讀入套件、自製工具和資料集**\n",
        "\n",
        "**這裡主要用 `OpenHowNet` 匯入語義(詞)資料庫,opencc-因為資料庫是簡字,所以需要繁轉簡，輸出可以再簡轉繁。**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2XUd8vStehUd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ddbf3e9-d75d-4598-d1d3-cf33b013a171"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vector_utils_advanced 模組載入完成！\n"
          ]
        }
      ],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import re\n",
        "import os\n",
        "import json\n",
        "import faiss\n",
        "import jieba\n",
        "import torch\n",
        "import openai\n",
        "import requests\n",
        "import importlib\n",
        "import OpenHowNet\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import gradio as gr\n",
        "import sememe_tools as st\n",
        "import matplotlib.pyplot as pltm\n",
        "import vector_utils_advanced as vu\n",
        "importlib.reload(vu)\n",
        "\n",
        "from tqdm import tqdm\n",
        "from pprint import pprint\n",
        "from opencc import OpenCC\n",
        "from datetime import datetime\n",
        "from google.colab import userdata\n",
        "from OpenHowNet import HowNetDict\n",
        "from datasets import load_dataset\n",
        "from collections import defaultdict\n",
        "from multi_turn_qa import multi_turn_qa\n",
        "from sklearn.preprocessing import normalize\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from anytree import Node, RenderTree, AsciiStyle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_X1eul7llVcf",
        "outputId": "fac445e0-c47e-454b-ef16-35c1315bfd50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'q': '柳江的主要支流的发源地是哪里？', 'path': [['柳江 ||| 2970218', '主要支流', '寨蒿河 ||| 7476446'], ['寨蒿河 ||| 7476446', '发源于', '贵州省黎平县高洋乡 ||| 0']]}\n"
          ]
        }
      ],
      "source": [
        "# 讀取 NLPCC-MH 資料集\n",
        "with open(\"/content/NLPCC-MH/data/nlpcc-mh.train.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    data = json.load(f)\n",
        "print(data[0])  # 確認第一筆內容"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r9YAU956yWT2"
      },
      "outputs": [],
      "source": [
        "# 讀取自製 Synonyms 資料\n",
        "with open(\"/content/sememe_synonym_OK.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    custom_synonyms = json.load(f)\n",
        "\n",
        "# 建立 custom_synonym_map, location_terms, weather_terms\n",
        "custom_synonym_map = {}\n",
        "location_terms = set()\n",
        "weather_terms = set()\n",
        "\n",
        "for key, entry in custom_synonyms.items():\n",
        "    zh_entry = entry.get(\"zh\", key)\n",
        "    zh_words = zh_entry if isinstance(zh_entry, list) else [zh_entry]\n",
        "\n",
        "    # 選第一個作為標準化詞\n",
        "    standard_word = st.normalize_text(zh_words[0])\n",
        "\n",
        "    # 主詞 + 同義詞都標準化\n",
        "    for word in zh_words:\n",
        "        if isinstance(word, str):\n",
        "            custom_synonym_map[st.normalize_text(word)] = standard_word\n",
        "    for syn in entry.get(\"synonyms\", []):\n",
        "        if isinstance(syn, str):\n",
        "            custom_synonym_map[st.normalize_text(syn)] = standard_word\n",
        "\n",
        "    # 分類地名與天氣詞\n",
        "    categories = entry.get(\"categories\", {})\n",
        "    target_set = location_terms if any(c in categories for c in [\"直轄市\", \"省轄市\", \"縣\", \"縣轄市\", \"區\", \"鎮\", \"鄉\"]) else weather_terms\n",
        "    for w in zh_words:\n",
        "        if isinstance(w, str):\n",
        "            target_set.add(st.normalize_text(w))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import re\n",
        "from collections import defaultdict\n",
        "\n",
        "# 扁平化資料結構\n",
        "def flatten_sememe_data(data, path=None, results=None):\n",
        "    if results is None:\n",
        "        results = {}\n",
        "    if path is None:\n",
        "        path = []\n",
        "    if isinstance(data, dict):\n",
        "        if \"items\" in data:\n",
        "            for item in data[\"items\"]:\n",
        "                key = item.get(\"id\") or item.get(\"zh\") or item.get(\"en\")\n",
        "                if not key:\n",
        "                    continue\n",
        "                linked = item.get(\"linked_sememe\", {})\n",
        "                synonyms = []\n",
        "                if isinstance(linked, dict):\n",
        "                    zh_syns = linked.get(\"zh\", [])\n",
        "                    en_syns = linked.get(\"en\", [])\n",
        "                    zh_syns = zh_syns if isinstance(zh_syns, list) else [zh_syns]\n",
        "                    en_syns = en_syns if isinstance(en_syns, list) else [en_syns]\n",
        "                    synonyms = list(set(filter(None, zh_syns + en_syns)))\n",
        "                results[key] = {\n",
        "                    \"zh\": item.get(\"zh\", \"\"),\n",
        "                    \"en\": item.get(\"en\", \"\"),\n",
        "                    \"synonyms\": synonyms,\n",
        "                    \"categories\": path.copy()\n",
        "                }\n",
        "        if \"categories\" in data:\n",
        "            for cat_name, cat_data in data[\"categories\"].items():\n",
        "                flatten_sememe_data(cat_data, path + [cat_name], results)\n",
        "    return results\n",
        "\n",
        "# 簡易文字正規化\n",
        "class SimpleNormalizer:\n",
        "    @staticmethod\n",
        "    def normalize_text(text):\n",
        "        return re.sub(r\"\\s+\", \"\", text.lower())\n",
        "\n",
        "st = SimpleNormalizer()\n",
        "\n",
        "# 類別定義與優先順序\n",
        "CATEGORY_TREE = {\n",
        "    \"geo_feature\": [\"地形地貌\", \"水文環境\", \"火山與地質\", \"海洋與沿岸\", \"國家公園與自然保護區\", \"特殊自然景觀\"],\n",
        "    \"climate\": [\"氣候\", \"氣候變遷\", \"季風\", \"乾季\", \"濕季\", \"氣候災害\"],\n",
        "    \"weather\": [\"天氣\", \"晴朗與雲量變化\", \"降水與雷雨現象\", \"特殊降水與冰雪現象\", \"能見度與空氣現象\", \"極端天氣與災害\", \"鋒面與氣候變化\", \"天氣現象\"],\n",
        "    \"location\": [\"直轄市\", \"省轄市\", \"縣\", \"縣轄市\", \"區\", \"鄉\", \"鎮\", \"城市\", \"都市區\", \"村\", \"里\", \"行政區\"]\n",
        "}\n",
        "CATEGORY_PRIORITY = [\"geo_feature\", \"climate\", \"weather\", \"location\"]\n",
        "\n",
        "# 語意矯正設定\n",
        "WEATHER_OVERRIDE = [\"冷鋒\", \"暖鋒\", \"滯留鋒\", \"鋒面雨\", \"雷陣雨\", \"短時強降雨\", \"間歇性小雨\", \"霜凍\", \"揚沙\", \"晴朗無雲\"]\n",
        "CLIMATE_EXCLUDE_FROM_WEATHER = [\"強降雨事件\", \"年降雨量\", \"梅雨季\"]\n",
        "\n",
        "# 精準分類 + 語意補正 + fallback 城市判斷\n",
        "def build_precise_maps(flattened_data):\n",
        "    category_term_sets = {cat: set() for cat in CATEGORY_TREE.keys()}\n",
        "    custom_synonym_map = {}\n",
        "    classified_terms = set()\n",
        "    unclassified_terms = set()\n",
        "    reclassified_terms = []\n",
        "\n",
        "    for key, entry in flattened_data.items():\n",
        "        zh_entry = entry.get(\"zh\", key)\n",
        "        synonyms = entry.get(\"synonyms\", [])\n",
        "        zh_words = zh_entry if isinstance(zh_entry, list) else [zh_entry]\n",
        "        standard_word = st.normalize_text(zh_words[0]) if zh_words else None\n",
        "        if not standard_word:\n",
        "            continue\n",
        "\n",
        "        for word in zh_words + synonyms:\n",
        "            if isinstance(word, str):\n",
        "                custom_synonym_map[st.normalize_text(word)] = standard_word\n",
        "\n",
        "        path = entry.get(\"categories\", [])\n",
        "        entry[\"classification\"] = []\n",
        "        entry[\"triggered_by\"] = []\n",
        "\n",
        "        classified = False\n",
        "        for cat in CATEGORY_PRIORITY:\n",
        "            keywords = CATEGORY_TREE[cat]\n",
        "            matched = [p for p in path if any(k in p for k in keywords)]\n",
        "            if matched:\n",
        "                entry[\"classification\"].append(cat)\n",
        "                entry[\"triggered_by\"].extend(matched)\n",
        "                category_term_sets[cat].add(standard_word)\n",
        "                classified_terms.add(standard_word)\n",
        "                classified = True\n",
        "                break\n",
        "\n",
        "        # fallback 城市詞尾判斷\n",
        "        if not classified:\n",
        "            location_suffixes = [\"市\", \"區\", \"鄉\", \"鎮\", \"村\", \"里\", \"島\"]\n",
        "            if any(isinstance(w, str) and w.endswith(tuple(location_suffixes)) for w in zh_words):\n",
        "                category_term_sets[\"location\"].add(standard_word)\n",
        "                entry[\"classification\"].append(\"location\")\n",
        "                entry[\"triggered_by\"].append(\"suffix_match\")\n",
        "                classified_terms.add(standard_word)\n",
        "                classified = True\n",
        "\n",
        "        if not classified:\n",
        "            unclassified_terms.add(standard_word)\n",
        "\n",
        "    # 語意矯正 weather 與 climate 的誤歸類\n",
        "    for word in list(classified_terms):\n",
        "        original = None\n",
        "        for cat, terms in category_term_sets.items():\n",
        "            if word in terms:\n",
        "                original = cat\n",
        "                break\n",
        "\n",
        "        if any(keyword in word for keyword in WEATHER_OVERRIDE):\n",
        "            if word not in CLIMATE_EXCLUDE_FROM_WEATHER and original != \"weather\":\n",
        "                if original:\n",
        "                    category_term_sets[original].remove(word)\n",
        "                category_term_sets[\"weather\"].add(word)\n",
        "                reclassified_terms.append((word, original, \"weather\"))\n",
        "\n",
        "    return custom_synonym_map, category_term_sets, classified_terms, unclassified_terms, reclassified_terms\n",
        "\n",
        "# 主程式\n",
        "with open(\"/content/sememe_synonym_OK.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    raw_data = json.load(f)\n",
        "\n",
        "taiwan_data = raw_data.get(\"Country\", {}).get(\"categories\", {}).get(\"Taiwan\", {})\n",
        "flattened_data = flatten_sememe_data(taiwan_data)\n",
        "\n",
        "custom_synonym_map, category_term_sets, classified_terms, unclassified_terms, reclassified_terms = build_precise_maps(flattened_data)\n",
        "\n",
        "# 結果輸出\n",
        "print(f\"\\n自訂 Synonym Map 已載入，共 {len(custom_synonym_map)} 筆\\n\")\n",
        "for cat, terms in category_term_sets.items():\n",
        "    print(f\"分類「{cat}」詞彙數量：{len(terms)}\")\n",
        "    print(f\"範例：{list(terms)[:10]}\\n\")\n",
        "\n",
        "total_classified = sum(len(terms) for terms in category_term_sets.values())\n",
        "print(f\"已分類詞彙總數：{total_classified}\")\n",
        "print(f\"未分類詞彙總數：{len(unclassified_terms)}\")\n",
        "if unclassified_terms:\n",
        "    print(f\"未分類範例：{list(unclassified_terms)[:10]}\")\n",
        "if reclassified_terms:\n",
        "    print(\"\\n語意矯正重新分類：\")\n",
        "    for word, from_cat, to_cat in reclassified_terms:\n",
        "        print(f\"    {word}：{from_cat} → {to_cat}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ac7Dzr6JOQjW",
        "outputId": "4b7ccf54-0239-43c8-87ef-c42af690cb2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ 自訂 Synonym Map 已載入，共 919 筆\n",
            "\n",
            "✅ 分類「geo_feature」詞彙數量：49\n",
            "範例：['墾丁國家公園', '中央山脈', '花蓮溪', '北海岸', '屏東平原', '合歡山', '曾文水庫', '南海岸', '大雪山', '墾丁珊瑚礁']\n",
            "\n",
            "✅ 分類「climate」詞彙數量：30\n",
            "範例：['山區氣候差異', '氣候災害應對', '乾季', '南部乾旱區', '東北季風影響', '熱帶氣候', '海岸氣候特徵', '亞熱帶氣候', '年降雨量', '微氣候分布']\n",
            "\n",
            "✅ 分類「weather」詞彙數量：40\n",
            "範例：['間歇性小雨', '冷鋒通過', '短時強降雨', '強雷陣雨', '大雨', '揚沙', '霜凍', '晴朗無雲', '暖鋒通過', '局部驟雨']\n",
            "\n",
            "✅ 分類「location」詞彙數量：322\n",
            "範例：['西港區', '彰化市', '義竹鄉', '光復鄉', '大埔鄉', '莿桐鄉', '臺西鄉', '綠島鄉', '西湖鄉', '樹林區']\n",
            "\n",
            "✅ 已分類詞彙總數：441\n",
            "✅ 未分類詞彙總數：0\n",
            "\n",
            "✅ 語意矯正重新分類：\n",
            "    暖鋒通過：climate → weather\n",
            "    鋒面雨：climate → weather\n",
            "    冷鋒通過：climate → weather\n",
            "    滯留鋒：climate → weather\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 設定 custom_synonym_map 和 custom_synonyms 給 sememe_tools\n",
        "st.set_custom_synonym_map(custom_synonym_map)\n",
        "st.set_custom_synonyms(custom_synonyms)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vec9xmigHbVp",
        "outputId": "bbdfbb9d-bedb-4dd4-8482-56229c2f816d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "自訂 Synonym Map 已載入，共 3 筆\n",
            "自訂 Synonyms 擴展資料已載入，共 1 筆\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4MspOblW1I6J"
      },
      "outputs": [],
      "source": [
        "# 處理 NLPCC-MH 單筆問答樣本\n",
        "def process_nlpccmh_sample(sample, base_id=\"nlpcc\", index=0):\n",
        "    result = []\n",
        "    question = sample[\"q\"]\n",
        "\n",
        "    sememe_analysis = st.analyze_sentence(question)\n",
        "    sememe_tags = sememe_analysis[\"sememe_tags\"]\n",
        "    sememe_map = sememe_analysis[\"sememe_map\"]\n",
        "\n",
        "    for path_id, triple in enumerate(sample.get(\"path\", [])):\n",
        "        head = triple[0].split(\" ||| \")[0]\n",
        "        relation = triple[1]\n",
        "        tail = triple[2].split(\" ||| \")[0]\n",
        "        sentence = f\"{head} {relation} {tail}\"\n",
        "\n",
        "        result.append({\n",
        "            \"id\": f\"{base_id}_{index}_{path_id}\",\n",
        "            \"question\": question,\n",
        "            \"question_sememe\": sememe_tags,\n",
        "            \"question_sememe_map\": sememe_map,\n",
        "            \"triple_sentence\": sentence,\n",
        "            \"head\": head,\n",
        "            \"relation\": relation,\n",
        "            \"tail\": tail\n",
        "        })\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y44Gexv60-mR"
      },
      "outputs": [],
      "source": [
        "# 分批處理整份資料集並輸出為 JSONL\n",
        "def process_nlpccmh_file(input_path, output_path, batch_size=1000):\n",
        "    with open(input_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    with open(output_path, \"w\", encoding=\"utf-8\") as out_f:\n",
        "        for i in range(0, len(data), batch_size):\n",
        "            batch = data[i:i + batch_size]\n",
        "            for j, sample in enumerate(tqdm(batch, desc=f\"Batch {i // batch_size}\")):\n",
        "                processed = process_nlpccmh_sample(sample, index=i + j)\n",
        "                for entry in processed:\n",
        "                    out_f.write(json.dumps(entry, ensure_ascii=False) + \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VwvfKNEllmkf"
      },
      "outputs": [],
      "source": [
        "# 啟動處理流程\n",
        "process_nlpccmh_file(\n",
        "    input_path=\"/content/NLPCC-MH/data/nlpcc-mh.train.json\",\n",
        "    output_path=\"/content/NLPCC-MH/data/nlpcc-mh.train_sememe.jsonl\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3H4OR5ApdiG"
      },
      "source": [
        "**測試**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "68wCnYISZZZy"
      },
      "outputs": [],
      "source": [
        "# 測試資料\n",
        "sememe_map = {\n",
        "    \"發源地\": [\"place|地方\", \"ComeToWorld|問世\"],\n",
        "    \"柳江\": [\"waters|水域\", \"China|中國\"]\n",
        "}\n",
        "question = \"柳江的主要支流的发源地是哪里？\"\n",
        "\n",
        "# 從 sememe_tool.py 調用 generate_augmented_query\n",
        "augmented_query = st.generate_augmented_query(question, sememe_map)\n",
        "\n",
        "# 顯示結果\n",
        "print(augmented_query)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrBsCaGR44mF"
      },
      "source": [
        "**執行嵌入和建立向量庫**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1w8Lz0of8XuU"
      },
      "outputs": [],
      "source": [
        "# 設定與模型初始化\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"BAAI/bge-base-zh\")\n",
        "hf_model = AutoModel.from_pretrained(\"BAAI/bge-base-zh\").to(device).eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KVy11SkjGIFt"
      },
      "outputs": [],
      "source": [
        "#構建 NLPCC-MH 擴充後的向量庫\n",
        "def prepare_nlpccmh_augmented_data(\n",
        "    input_path, index_path, meta_path, model, tokenizer, device, pooling=\"cls\"\n",
        "):\n",
        "    assert os.path.exists(input_path), f\"找不到輸入檔案: {input_path}\"\n",
        "\n",
        "    texts, ids, metas = [], [], []\n",
        "    with open(input_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        for i, line in enumerate(tqdm(f, desc=\"處理 NLPCC-MH 資料\")):\n",
        "            entry = json.loads(line.strip())\n",
        "            question = entry[\"question\"]\n",
        "            sememe_map = entry[\"question_sememe_map\"]\n",
        "\n",
        "            pseudo_text = \"；\".join(st.format_sememe_map(sememe_map, style=\"display\"))\n",
        "            merged_query = st.generate_augmented_query(question, sememe_map)\n",
        "\n",
        "            texts.append(merged_query)\n",
        "            ids.append(entry[\"id\"])\n",
        "            metas.append({\n",
        "                \"query\": question,\n",
        "                \"sememe\": pseudo_text\n",
        "            })\n",
        "\n",
        "    vu.build_faiss_index_and_save(\n",
        "        texts=texts,\n",
        "        ids=ids,\n",
        "        meta_list=metas,\n",
        "        model=model,\n",
        "        tokenizer=tokenizer,\n",
        "        device=device,\n",
        "        index_path=index_path,\n",
        "        meta_path=meta_path,\n",
        "        pooling=pooling\n",
        "    )\n",
        "\n",
        "    print(f\"NLPCC-MH向量庫已建置完成，共 {len(texts)} 筆資料。\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8by82RzmJlh9"
      },
      "outputs": [],
      "source": [
        "# 處理自製同義詞資料，建立向量庫\n",
        "def prepare_custom_augmented_data(synonym_path, index_path, meta_path, model, tokenizer, device, pooling=\"cls\"):\n",
        "    assert os.path.exists(synonym_path), f\"找不到輸入檔案: {synonym_path}\"\n",
        "\n",
        "    texts, ids, metas = [], [], []\n",
        "    with open(synonym_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        synonym_data = json.load(f)\n",
        "\n",
        "    for i, (key, entry) in enumerate(tqdm(synonym_data.items(), desc=\"處理自製同義詞資料\")):\n",
        "        zh_entry = entry.get(\"zh\", key)\n",
        "        synonyms = entry.get(\"synonyms\", [])\n",
        "        categories = entry.get(\"categories\", {})\n",
        "\n",
        "        if isinstance(zh_entry, list):\n",
        "            standard_word = zh_entry[0]\n",
        "            parts = zh_entry.copy()\n",
        "        else:\n",
        "            standard_word = zh_entry\n",
        "            parts = [zh_entry]\n",
        "\n",
        "        parts.extend(synonyms)\n",
        "\n",
        "        description = \"、\".join(parts) + \"。這些是相關語義擴展資訊。\"\n",
        "        merged = f\"[Q] {standard_word} [SEP] {description}\"\n",
        "\n",
        "        texts.append(merged)\n",
        "        ids.append(f\"custom_{i}\")\n",
        "        metas.append({\n",
        "            \"term\": standard_word,\n",
        "            \"synonyms\": synonyms,\n",
        "            \"categories\": categories,\n",
        "            \"is_location\": False\n",
        "        })\n",
        "\n",
        "        for cat_name, city_list in categories.items():\n",
        "            for city in city_list:\n",
        "                texts.append(f\"[Q] {city} [SEP] {standard_word}地區\")\n",
        "                ids.append(f\"city_{i}_{city}\")\n",
        "                metas.append({\n",
        "                    \"term\": city,\n",
        "                    \"synonyms\": [],\n",
        "                    \"categories\": {},\n",
        "                    \"is_location\": True\n",
        "                })\n",
        "\n",
        "    vu.build_faiss_index_and_save(\n",
        "        texts=texts,\n",
        "        ids=ids,\n",
        "        meta_list=metas,\n",
        "        model=model,\n",
        "        tokenizer=tokenizer,\n",
        "        device=device,\n",
        "        index_path=index_path,\n",
        "        meta_path=meta_path,\n",
        "        pooling=pooling\n",
        "    )\n",
        "    print(f\"自製 Synonym 向量庫已建置完成，共 {len(texts)} 筆資料。\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t_yI9cgtz-Cg"
      },
      "outputs": [],
      "source": [
        "# 建立 NLPCC-MH 與自製 Synonyms 向量庫\n",
        "def run_all_indexing(nlpcc_input_path,nlpcc_index_path,nlpcc_meta_path,synonym_path,custom_index_path,custom_meta_path,model,tokenizer,device):\n",
        "    print(\"開始全流程向量庫建立...\")\n",
        "\n",
        "    # 先建立 NLPCC\n",
        "    print(\"\\n開始建立 NLPCC-MH 向量庫...\")\n",
        "    prepare_nlpccmh_augmented_data(\n",
        "        input_path=nlpcc_input_path,\n",
        "        index_path=nlpcc_index_path,\n",
        "        meta_path=nlpcc_meta_path,\n",
        "        model=model,\n",
        "        tokenizer=tokenizer,\n",
        "        device=device)\n",
        "    # 建立 Custom\n",
        "    print(\"\\n開始建立自製 Synonym 向量庫...\")\n",
        "    prepare_custom_augmented_data(\n",
        "        synonym_path=synonym_path,\n",
        "        index_path=custom_index_path,\n",
        "        meta_path=custom_meta_path,\n",
        "        model=model,\n",
        "        tokenizer=tokenizer,\n",
        "        device=device)\n",
        "    print(\"\\n全部向量庫建立完成！\")\n",
        "# 執行建立向量資料庫\n",
        "run_all_indexing(nlpcc_input_path=\"/content/NLPCC-MH/data/nlpcc-mh.train_sememe.jsonl\",nlpcc_index_path=\"/content/index.faiss\",nlpcc_meta_path=\"/content/metadata.jsonl\",synonym_path=\"/content/sememe_synonym.json\",custom_index_path=\"/content/custom_index.faiss\",custom_meta_path=\"/content/custom_metadata.jsonl\",model=hf_model,tokenizer=tokenizer,device=device)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**查詢測試**"
      ],
      "metadata": {
        "id": "eCfwXaX9dUUN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 載入所有索引\n",
        "index_paths = [(\"/content/index.faiss\", \"/content/metadata.jsonl\"),(\"/content/custom_index.faiss\", \"/content/custom_metadata.jsonl\")]\n",
        "\n",
        "indices, metadatas = [], []\n",
        "for idx_path, meta_path in index_paths:\n",
        "    index, meta = vu.load_index_and_metadata(idx_path, meta_path)\n",
        "    indices.append(index)\n",
        "    metadatas.append(meta)\n",
        "\n",
        "print(f\"成功載入 {len(indices)} 個索引庫！\")\n",
        "\n",
        "# 查詢\n",
        "query = \"[Q] 柳江的主要支流的发源地是哪里？ [SEP] 發源地 含有語意「place|地方、ComeToWorld|問世」；柳江 含有語意「waters|水域、China|中國」\"\n",
        "\n",
        "# 單一庫查詢\n",
        "single_results = vu.search_with_metadata(\n",
        "    query=query,\n",
        "    index=indices[0],\n",
        "    metadata=metadatas[0],\n",
        "    model=hf_model,\n",
        "    tokenizer=tokenizer,\n",
        "    device=device,\n",
        "    topk=3\n",
        ")\n",
        "\n",
        "print(\"\\n單一庫查詢結果：\")\n",
        "for r in single_results:\n",
        "    print(f\"匹配 ID: {r['id']}｜分數: {r['score']:.4f}\")\n",
        "    print(f\"原始問句/詞: {r['meta'].get('query', r['meta'].get('term', '')).strip()}\")\n",
        "    print(f\"語義描述: {r['meta'].get('sememe', r['meta'].get('synonyms', ''))}\\n\")\n",
        "\n",
        "# 多庫整合查詢\n",
        "combined_results = vu.combine_search(\n",
        "    query=query,\n",
        "    indices=indices,\n",
        "    metadatas=metadatas,\n",
        "    model=hf_model,\n",
        "    tokenizer=tokenizer,\n",
        "    device=device,\n",
        "    topk=5\n",
        ")\n",
        "\n",
        "print(\"多庫整合查詢結果：\")\n",
        "for r in combined_results:\n",
        "    print(f\"來自：{r['source']}｜匹配 ID: {r['id']}｜分數: {r['score']:.4f}\")\n",
        "    print(f\"原始問句/詞: {r['meta'].get('query', r['meta'].get('term', '')).strip()}\")\n",
        "    print(f\"語義描述: {r['meta'].get('sememe', r['meta'].get('synonyms', ''))}\\n\")"
      ],
      "metadata": {
        "id": "sxrBphuSdHAH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0G3uR2Z0-lHP"
      },
      "outputs": [],
      "source": [
        "# 將檢索結果整理為 RAG 輸入格式。\n",
        "def build_rag_prompt(query, retrieved_results, mode=\"standard\"):\n",
        "    context_parts = []\n",
        "    for r in retrieved_results:\n",
        "        if mode == \"standard\":\n",
        "            context_parts.append(\n",
        "                f\"- 問句：{r['meta'].get('query', r['text'])}\\n  語義：{r['meta'].get('sememe', '')}\"\n",
        "            )\n",
        "        elif mode == \"flat\":\n",
        "            context_parts.append(r['text'])\n",
        "\n",
        "    context_block = \"\\n\\n\".join(context_parts)\n",
        "    prompt = f\"你是一個中文問答助理，請根據下列檢索到的語意資訊，回答原始問題：\\n\\n{context_block}\\n\\n🔸 原始問題：{query}\\n\\n✅ 請用自然語言回答：\"\n",
        "    return prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uf9Ms5W-PSH4"
      },
      "outputs": [],
      "source": [
        "# 取得 API 金鑰與 headers\n",
        "api_key = userdata.get(\"Groq\")\n",
        "headers = {\n",
        "    \"Authorization\": f\"Bearer {api_key}\",\n",
        "    \"Content-Type\": \"application/json\"\n",
        "}\n",
        "\n",
        "# 取得模型列表\n",
        "r = requests.get(\"https://api.groq.com/openai/v1/models\", headers=headers)\n",
        "data = r.json()\n",
        "groq_model_id = data.get(\"data\", [])\n",
        "df = pd.DataFrame(groq_model_id)\n",
        "if \"id\" in df.columns:\n",
        "    df = df[[\"id\"]]\n",
        "    df.reset_index(drop=True, inplace=True)\n",
        "    df.index += 1\n",
        "    display(df)\n",
        "\n",
        "# 指定使用模型\n",
        "groq_model_id =\"meta-llama/llama-4-maverick-17b-128e-instruct\"\n",
        "base_url = \"https://api.groq.com/openai/v1\"\n",
        "os.environ[\"OPENAI_API_KEY\"] = api_key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GceIlZrKQMuI"
      },
      "outputs": [],
      "source": [
        "# 載入索引\n",
        "index1, meta1 = vu.load_index_and_metadata(index_path=\"/content/index.faiss\",meta_path=\"/content/metadata.jsonl\")\n",
        "index2, meta2 = vu.load_index_and_metadata(index_path=\"/content/custom_index.faiss\",meta_path=\"/content/custom_metadata.jsonl\")\n",
        "\n",
        "# 查詢問題\n",
        "query = \"柳江的主要支流的發源地是？\"\n",
        "\n",
        "# 用向量庫檢索（單輪查詢）\n",
        "search_results = vu.search_with_metadata(\n",
        "    query=query,\n",
        "    index=index1,\n",
        "    metadata=meta1,\n",
        "    model=hf_model,\n",
        "    tokenizer=tokenizer,\n",
        "    device=device,\n",
        "    topk=3\n",
        ")\n",
        "\n",
        "print(\"單輪檢索結果：\")\n",
        "for r in search_results:\n",
        "    print(f\"- 匹配分數: {r['score']:.4f} ｜內容: {r['text'][:50]}...\")\n",
        "\n",
        "# 多回合 QA（使用兩個索引）\n",
        "history = multi_turn_qa(initial_query=query,index_list=[(index1, meta1), (index2, meta2)],model=hf_model,tokenizer=tokenizer,device=device,api_key=api_key,max_turns=3,topk=5)\n",
        "\n",
        "# 顯示整個對話紀錄\n",
        "print(\"\\n多回合問答紀錄：\")\n",
        "for record in history:\n",
        "    print(f\"\\n問題：{record['query']}\")\n",
        "    print(f\"回答：{record['answer']}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 載入 API 金鑰\n",
        "api_keyW = userdata.get(\"天氣\")\n",
        "\n",
        "# 繁簡轉換\n",
        "cc_sp2tw = OpenCC('s2twp')\n",
        "\n",
        "# 文字正規化\n",
        "def normalize_text(text):\n",
        "    return cc_sp2tw.convert(text).replace(\"台\", \"臺\").lower().strip()\n",
        "\n",
        "# 問句預處理\n",
        "def preprocess_query(query):\n",
        "    query = normalize_text(query)\n",
        "    useless_words = [\"請問\", \"今天\", \"現在\", \"呢\", \"的\", \"請\", \"一下\", \"目前\", \"嗎\", \"呢？\", \"？\"]\n",
        "    for word in useless_words:\n",
        "        query = query.replace(word, \"\")\n",
        "    return query"
      ],
      "metadata": {
        "id": "Sdcqhry78Obu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pq2Dwa8ZWXAl"
      },
      "outputs": [],
      "source": [
        "# 繁簡轉換 + 清洗\n",
        "cc_sp2tw = OpenCC('s2twp')\n",
        "\n",
        "def normalize_text(text):\n",
        "    return cc_sp2tw.convert(text).replace(\"台\", \"臺\").lower().strip()\n",
        "\n",
        "def preprocess_query(query):\n",
        "    query = cc_sp2tw.convert(query)   # 繁簡轉換\n",
        "    query = query.replace(\"台\", \"臺\").lower().strip()\n",
        "\n",
        "    noise_words = [\"請問\", \"一下\", \"呢\", \"嗎\", \"？\", \"呢？\", \"呢嗎\", \"請\"]\n",
        "    for word in noise_words:\n",
        "        query = query.replace(word, \"\")\n",
        "    return query"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 文本向量化\n",
        "def encode_texts(texts, model, tokenizer, device, pooling=\"cls\", normalize_vec=True, batch_size=64):\n",
        "    if isinstance(texts, str):\n",
        "        texts = [texts]\n",
        "\n",
        "    all_embeddings = []\n",
        "    for i in range(0, len(texts), batch_size):\n",
        "        batch = texts[i:i+batch_size]\n",
        "        encodings = tokenizer(batch, padding=True, truncation=True, return_tensors=\"pt\", max_length=64).to(device)\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**encodings)\n",
        "        if pooling == \"cls\":\n",
        "            embeddings = outputs.last_hidden_state[:, 0]\n",
        "        else:\n",
        "            mask = encodings[\"attention_mask\"].unsqueeze(-1).expand(outputs.last_hidden_state.size()).float()\n",
        "            embeddings = (outputs.last_hidden_state * mask).sum(1) / mask.sum(1).clamp(min=1e-9)\n",
        "        all_embeddings.append(embeddings.cpu())\n",
        "\n",
        "    all_embeddings = torch.cat(all_embeddings, dim=0).numpy()\n",
        "    return normalize(all_embeddings) if normalize_vec else all_embeddings"
      ],
      "metadata": {
        "id": "eTcCih0REsgb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9HcmW6u1hOlq"
      },
      "outputs": [],
      "source": [
        "# 查詢向量庫\n",
        "def query_custom_sememe(query, index, metas, model, tokenizer, device, topk=10, pooling=\"cls\", min_score=0.3):\n",
        "    clean_query = preprocess_query(query)\n",
        "    query_vec = encode_texts(clean_query, model, tokenizer, device, pooling)\n",
        "\n",
        "    D, I = index.search(query_vec, topk)\n",
        "\n",
        "    results = []\n",
        "    for score, idx in zip(D[0], I[0]):\n",
        "        if idx >= 0 and score >= min_score:\n",
        "            meta = metas[idx]\n",
        "            text = meta.get(\"term\") or meta.get(\"query\") or \"\"  # ⚡ 重點！安全 fallback\n",
        "            results.append({\n",
        "                \"score\": float(score),\n",
        "                \"text\": text,\n",
        "                \"sememe\": meta.get(\"sememe\", \"\"),\n",
        "                \"is_location\": meta.get(\"is_location\", False)\n",
        "            })\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 地名簡化映射表\n",
        "def build_city_alias_map(metas):\n",
        "    alias_map = {}\n",
        "    for meta in metas:\n",
        "        if meta.get(\"is_location\"):\n",
        "            original = meta.get(\"term\", \"\")\n",
        "            if original:\n",
        "                alias_map[original.replace(\"台\", \"臺\")] = original\n",
        "                short = original.replace(\"臺\", \"台\").replace(\"市\", \"\").replace(\"縣\", \"\")\n",
        "                alias_map[short] = original\n",
        "    return alias_map\n",
        "\n",
        "# term-sememe對應表\n",
        "def build_term_sememe_map(metas):\n",
        "    term_map = {}\n",
        "    for meta in metas:\n",
        "        term = meta.get(\"term\", \"\")\n",
        "        sememe = meta.get(\"sememe\", \"\")\n",
        "        if term and sememe:\n",
        "            term_map[term] = sememe\n",
        "    return term_map\n",
        "\n",
        "# 地名fallback修正\n",
        "def fix_location_name(name, city_alias_map):\n",
        "    for key, val in city_alias_map.items():\n",
        "        if key in name:\n",
        "            return val\n",
        "    return name"
      ],
      "metadata": {
        "id": "JqXUkZU78eRj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 天氣API查詢\n",
        "def fetch_weather(location, api_keyW):\n",
        "    try:\n",
        "        url = f\"http://api.openweathermap.org/data/2.5/weather?q={location}&appid={api_keyW}&units=metric&lang=zh_tw\"\n",
        "        response = requests.get(url, timeout=5)\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "        return {\n",
        "            \"condition\": data[\"weather\"][0][\"description\"],\n",
        "            \"temperature\": data[\"main\"][\"temp\"],\n",
        "            \"humidity\": data[\"main\"][\"humidity\"],\n",
        "            \"pressure\": data[\"main\"][\"pressure\"],\n",
        "            \"wind_speed\": data[\"wind\"][\"speed\"]\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f\"天氣API錯誤: {e} | 位置：{location}\")\n",
        "        return None\n",
        "\n",
        "# 格式化回覆\n",
        "def format_weather_reply(weather_data, location):\n",
        "    if not weather_data:\n",
        "        return f\"無法取得 {location} 的天氣資料。\"\n",
        "    return (\n",
        "        f\"{location} 天氣概況：\\n\"\n",
        "        f\"狀態：{weather_data['condition']}\\n\"\n",
        "        f\"氣溫：{weather_data['temperature']}°C\\n\"\n",
        "        f\"濕度：{weather_data['humidity']}%\\n\"\n",
        "        f\"風速：{weather_data['wind_speed']} m/s\\n\"\n",
        "        f\"氣壓：{weather_data['pressure']} hPa\"\n",
        "    )"
      ],
      "metadata": {
        "id": "DcUDijm-8iM0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 向量檢索 + 地名修正 + fallback回覆\n",
        "def handle_weather_query(user_query, index, metas, model, tokenizer, device, city_alias_map, term_sememe_map, api_keyW, topk=10, min_score=0.3):\n",
        "    results = query_custom_sememe(user_query, index, metas, model, tokenizer, device, topk=topk, min_score=min_score)\n",
        "\n",
        "    found_locations = []\n",
        "    found_weather = False\n",
        "\n",
        "    vague_terms = {\"城市\", \"市區\", \"都市\", \"都會區\", \"市鎮\"}\n",
        "\n",
        "    for r in results:\n",
        "        if r[\"is_location\"] and r[\"text\"] not in vague_terms:\n",
        "            fixed_location = fix_location_name(r[\"text\"], city_alias_map)\n",
        "            found_locations.append(fixed_location)\n",
        "        elif not r[\"is_location\"] and (\"天氣\" in r[\"sememe\"] or \"氣候\" in r[\"sememe\"]):\n",
        "            found_weather = True\n",
        "\n",
        "    found_locations = list(set(found_locations))\n",
        "\n",
        "    if found_locations and found_weather:\n",
        "        replies = []\n",
        "        for loc in found_locations:\n",
        "            weather_data = fetch_weather(loc, api_keyW)\n",
        "            reply = format_weather_reply(weather_data, loc)\n",
        "            replies.append(reply)\n",
        "        return \"\\n\\n\".join(replies)\n",
        "\n",
        "    elif found_weather and not found_locations:\n",
        "        return \"請問您想查詢哪個城市或地區的天氣呢？\"\n",
        "\n",
        "    elif found_locations and not found_weather:\n",
        "        replies = []\n",
        "        for loc in found_locations:\n",
        "            weather_data = fetch_weather(loc, api_keyW)\n",
        "            reply = format_weather_reply(weather_data, loc)\n",
        "            replies.append(reply)\n",
        "        return \"\\n\\n\".join(replies)\n",
        "\n",
        "    else:\n",
        "        return \"目前無法辨識您的問題是否與天氣有關，請重新描述地點與內容。\""
      ],
      "metadata": {
        "id": "Z3O47fvF8ukc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 載入 custom index\n",
        "index_custom = faiss.read_index(\"/content/custom_index.faiss\")\n",
        "with open(\"/content/custom_metadata.jsonl\", \"r\", encoding=\"utf-8\") as f:\n",
        "    meta_custom = [json.loads(line) for line in f]\n",
        "\n",
        "# 製作 alias_map 和 sememe_map\n",
        "city_alias_map = build_city_alias_map(meta_custom)\n",
        "term_sememe_map = build_term_sememe_map(meta_custom)\n",
        "\n",
        "# 初始化 tokenizer + model\n",
        "model_name = \"BAAI/bge-base-zh\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModel.from_pretrained(model_name).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device = next(model.parameters()).device"
      ],
      "metadata": {
        "id": "x-VsUYzfHJqD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 測試簡版\n",
        "query = \"今天台中會下雨嗎？\"\n",
        "print(preprocess_query(query))  # --> 確認有臺中和下雨字眼\n",
        "results = query_custom_sememe(query, index_custom, meta_custom, model, tokenizer, device, topk=10, min_score=0.2)\n",
        "\n",
        "for r in results:\n",
        "    print(r)"
      ],
      "metadata": {
        "id": "aw_4_XxNNYV4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 測試\n",
        "user_query = \"今天台中會下雨嗎？\"\n",
        "final_answer = handle_weather_query(user_query, index_custom, meta_custom, model, tokenizer, device, city_alias_map, term_sememe_map, api_keyW)\n",
        "print(final_answer)"
      ],
      "metadata": {
        "id": "waMRhV5iHMh0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 調用 Groq API，根據檢索結果生成強化回答\n",
        "def generate_answer_with_groq(user_input, results, api_key, model=\"mixtral-8x7b-32768\", temperature=0.2):\n",
        "    context_block = \"\"\n",
        "    for idx, r in enumerate(results):\n",
        "        query = r['meta'].get('query', '')\n",
        "        sememe = r['meta'].get('sememe', '')\n",
        "        context_block += f\"[{idx+1}] {query} | {sememe}\\n\"\n",
        "\n",
        "    prompt = (\n",
        "        f\"請根據以下已知資訊，回答用戶的問題。\\n\\n\"\n",
        "        f\"===已知知識===\\n{context_block}\\n\\n\"\n",
        "        f\"===用戶提問===\\n{user_input}\\n\\n\"\n",
        "        f\"請保持簡潔、清楚，並避免編造。\"\n",
        "    )\n",
        "\n",
        "    url = \"https://api.groq.com/openai/v1/chat/completions\"\n",
        "    headers = {\n",
        "        \"Authorization\": f\"Bearer {api_key}\",\n",
        "        \"Content-Type\": \"application/json\"\n",
        "    }\n",
        "    payload = {\n",
        "        \"model\": model,\n",
        "        \"messages\": [\n",
        "            {\"role\": \"system\", \"content\": \"你是一位專業的中文問答助手。\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        \"temperature\": temperature,\n",
        "        \"top_p\": 1.0,\n",
        "        \"max_tokens\": 1024,\n",
        "        \"n\": 1\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        response = requests.post(url, headers=headers, json=payload, timeout=15)\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "        return data[\"choices\"][0][\"message\"][\"content\"]\n",
        "    except Exception as e:\n",
        "        print(f\"Groq API失敗: {e}\")\n",
        "        return \"目前無法取得回答，請稍後再試。\""
      ],
      "metadata": {
        "id": "_lYGol1su4FL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def master_pipeline(user_input):\n",
        "    if is_weather_query(user_input):\n",
        "        return handle_weather_query(\n",
        "            user_query=user_input,\n",
        "            index=index_custom,\n",
        "            metas=meta_custom,\n",
        "            model=model_vector,\n",
        "            tokenizer=tokenizer_vector,\n",
        "            device=device_vector,\n",
        "            city_alias_map=city_alias_map,\n",
        "            term_sememe_map=term_sememe_map,\n",
        "            api_keyW=api_keyW,\n",
        "            topk=10,\n",
        "            min_score=0.3\n",
        "        )\n",
        "    else:\n",
        "        results = combine_search(\n",
        "            query=user_input,\n",
        "            indices=[index_nlpcc, index_custom],\n",
        "            metadatas=[meta_nlpcc, meta_custom],\n",
        "            model_vector=model_vector,\n",
        "            tokenizer_vector=tokenizer_vector,\n",
        "            device_vector=device_vector,\n",
        "            topk=5\n",
        "        )\n",
        "        return generate_answer_with_groq(user_input, results, api_key, model=groq_model_id)"
      ],
      "metadata": {
        "id": "3boadZuouZa6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 載入向量庫與metadata\n",
        "index_nlpcc, meta_nlpcc = vu.load_index_and_metadata(\"/content/index.faiss\", \"/content/metadata.jsonl\")\n",
        "index_custom, meta_custom = vu.load_index_and_metadata(\"/content/custom_index.faiss\", \"/content/custom_metadata.jsonl\")\n",
        "\n",
        "# 載入天氣向量庫\n",
        "index_weather, meta_weather = vu.load_index_and_metadata(\"/content/weather_sememe_index.faiss\", \"/content/weather_sememe_metadata.jsonl\")\n",
        "\n",
        "# 載入知識庫用向量化模型\n",
        "model_vector_name = \"BAAI/bge-base-zh\"\n",
        "tokenizer_vector = AutoTokenizer.from_pretrained(model_vector_name)\n",
        "model_vector = AutoModel.from_pretrained(model_vector_name).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device_vector = next(model_vector.parameters()).device"
      ],
      "metadata": {
        "id": "60lMM16NuV2K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WcuxTDSOg_Fi"
      },
      "outputs": [],
      "source": [
        "# 測試\n",
        "user_question = \"今天台中會下雨嗎？\"\n",
        "final_answer = master_pipeline(user_question)\n",
        "print(final_answer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VaOBErHbTDCU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "outputId": "624dbc67-4e83-4ba7-bbeb-5037cff0ce06"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "Exception",
          "evalue": "Failed to download file. Status code: 400",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-f0622ea36bd6>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"https://raw.githubusercontent.com/your_repo/your_logo.png\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Logo（可以換網址或放本地）\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mchatbot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mChatbot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"天氣型 AI 智能助理\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/gradio/component_meta.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/gradio/components/image.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, value, format, height, width, image_mode, sources, type, label, every, inputs, show_label, show_download_button, container, scale, min_width, interactive, visible, streaming, elem_id, elem_classes, render, key, mirror_webcam, webcam_options, show_share_button, placeholder, show_fullscreen_button, webcam_constraints)\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplaceholder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m         super().__init__(\n\u001b[0m\u001b[1;32m    180\u001b[0m             \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0mevery\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevery\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/gradio/components/base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mStreamingInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetaclass\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mabc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mABCMeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mabc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/gradio/component_meta.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/gradio/components/base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, value, label, info, show_label, container, scale, min_width, interactive, visible, elem_id, elem_classes, render, key, load_fn, every, inputs)\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseModel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0minitial_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitial_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_dump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m         self.value = move_files_to_cache(\n\u001b[0m\u001b[1;32m    228\u001b[0m             \u001b[0minitial_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/gradio/processing_utils.py\u001b[0m in \u001b[0;36mmove_files_to_cache\u001b[0;34m(data, block, postprocess, check_in_upload_folder, keep_in_cache)\u001b[0m\n\u001b[1;32m    525\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_dump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 527\u001b[0;31m     return client_utils.traverse(\n\u001b[0m\u001b[1;32m    528\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_move_to_cache\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclient_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_file_obj_with_meta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/gradio_client/utils.py\u001b[0m in \u001b[0;36mtraverse\u001b[0;34m(json_obj, func, is_root)\u001b[0m\n\u001b[1;32m   1103\u001b[0m     \"\"\"\n\u001b[1;32m   1104\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_root\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1105\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1106\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1107\u001b[0m         \u001b[0mnew_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/gradio/processing_utils.py\u001b[0m in \u001b[0;36m_move_to_cache\u001b[0;34m(d)\u001b[0m\n\u001b[1;32m    499\u001b[0m                 \u001b[0m_check_allowed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpayload\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_in_upload_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mpayload\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_stream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 501\u001b[0;31m                 \u001b[0mtemp_file_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmove_resource_to_block_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpayload\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    502\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtemp_file_path\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Did not determine a file path for the resource.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\u001b[0m in \u001b[0;36mmove_resource_to_block_cache\u001b[0;34m(self, url_or_file_path)\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mclient_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_http_url_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_or_file_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m             temp_file_path = processing_utils.save_url_to_cache(\n\u001b[0m\u001b[1;32m    345\u001b[0m                 \u001b[0murl_or_file_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGRADIO_CACHE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/gradio/processing_utils.py\u001b[0m in \u001b[0;36mssrf_protected_download\u001b[0;34m(url, cache_dir)\u001b[0m\n\u001b[1;32m    396\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munsafe_download\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m         return client_utils.synchronize_async(\n\u001b[0m\u001b[1;32m    399\u001b[0m             \u001b[0masync_ssrf_protected_download\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/gradio_client/utils.py\u001b[0m in \u001b[0;36msynchronize_async\u001b[0;34m(func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m     \"\"\"\n\u001b[0;32m--> 890\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfsspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masyn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfsspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masyn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    891\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/fsspec/asyn.py\u001b[0m in \u001b[0;36msync\u001b[0;34m(loop, func, timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mFSTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mreturn_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreturn_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseException\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mreturn_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mreturn_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/fsspec/asyn.py\u001b[0m in \u001b[0;36m_runner\u001b[0;34m(event, coro, result, timeout)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mcoro\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoro\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mcoro\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/gradio/processing_utils.py\u001b[0m in \u001b[0;36masync_ssrf_protected_download\u001b[0;34m(url, cache_dir)\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 361\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Failed to download file. Status code: {response.status_code}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m     \u001b[0;32masync\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0maiofiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_temp_file_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mException\u001b[0m: Failed to download file. Status code: 400"
          ]
        }
      ],
      "source": [
        "# Chat 主邏輯\n",
        "def chat_with_agent(user_input, history):\n",
        "    history = history or []\n",
        "    reply = master_pipeline(user_input)\n",
        "    history.append((user_input, reply))\n",
        "    return history, history\n",
        "\n",
        "# 啟動 Gradio\n",
        "with gr.Blocks(theme=gr.themes.Base(primary_hue=\"cyan\")) as demo:\n",
        "    gr.Markdown(\"\"\"\n",
        "    # 中文語義問答助理 + 天氣小幫手\n",
        "     支援即時天氣查詢\n",
        "     支援語義擴展推理\n",
        "     RAG + LLM 智能生成\n",
        "    \"\"\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=1):\n",
        "            gr.Image(value=\"https://raw.githubusercontent.com/your_repo/your_logo.png\", height=100)  # Logo（可以換網址或放本地）\n",
        "        with gr.Column(scale=5):\n",
        "            chatbot = gr.Chatbot(height=500, label=\"天氣型 AI 智能助理\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=4):\n",
        "            user_input = gr.Textbox(\n",
        "                placeholder=\"請輸入問題，例如：明天高雄會下雨嗎？\",\n",
        "                show_label=False\n",
        "            )\n",
        "        with gr.Column(scale=1, min_width=80):\n",
        "            submit_btn = gr.Button(\"送出\", variant=\"primary\")\n",
        "\n",
        "    clear_btn = gr.Button(\"🧹 清除對話\", variant=\"secondary\")\n",
        "\n",
        "    # 綁定交互\n",
        "    history_state = gr.State([])\n",
        "\n",
        "    submit_btn.click(\n",
        "        chat_with_agent,\n",
        "        inputs=[user_input, history_state],\n",
        "        outputs=[chatbot, history_state]\n",
        "    )\n",
        "    user_input.submit(\n",
        "        chat_with_agent,\n",
        "        inputs=[user_input, history_state],\n",
        "        outputs=[chatbot, history_state]\n",
        "    )\n",
        "    clear_btn.click(lambda: ([], []), inputs=None, outputs=[chatbot, history_state])\n",
        "\n",
        "# 啟動服務\n",
        "demo.launch(share=True)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}